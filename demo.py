import streamlit as st
import torch
import numpy as np
import os
import cv2
import io
from PIL import Image
from torchvision import tv_tensors
import torch.nn.functional as Fnn
from google.genai import types

# Import c√°c h√†m t·ª´ file c·ªßa b·∫°n
from finetune import get_model, get_transform 
from prompt import client # ƒê·∫£m b·∫£o file prompt.py ƒë√£ c·∫•u h√¨nh client genai

# --- C·∫§U H√åNH ---
MY_PALETTE = {
    (0,0,0): 0,
    (240,240,13): 1,
    (233,117,5): 2,
    (8,182,8): 3,    
}
ID2COLOR = {v: k for k, v in MY_PALETTE.items()}
CLASS_NAMES = ['M√†ng nhƒ© ph·∫£i b√¨nh th∆∞·ªùng', 'M√†ng nhƒ© tr√°i b√¨nh th∆∞·ªùng', 'Vi√™m tai gi·ªØa c·∫•p', 'Vi√™m tai gi·ªØa m·∫°n t√≠nh', 'Vi√™m tai gi·ªØa ti·∫øt d·ªãch' ]



# --- H√ÄM H·ªñ TR·ª¢ ---
@st.cache_resource
def load_model(checkpoint_path):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = get_model(4, 5)
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['state_dict'])
    model.to(device)
    model.eval()
    return model, device

def draw_polygon_overlay(img_np, mask_np, alpha=0.4):
    if torch.is_tensor(mask_np):
        mask_np = mask_np.cpu().numpy()
    
    overlay_fill = img_np.copy()
    img_out = img_np.copy()

    for class_id in range(1, 4): # 1, 2, 3
        class_mask = (mask_np == class_id).astype(np.uint8) * 255
        if np.sum(class_mask) == 0: continue

        kernel = np.ones((3,3), np.uint8)
        class_mask = cv2.morphologyEx(class_mask, cv2.MORPH_OPEN, kernel)
        contours, _ = cv2.findContours(class_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        color = ID2COLOR.get(class_id, (255, 255, 255))
        cv2.fillPoly(overlay_fill, contours, color)
        cv2.polylines(img_out, contours, isClosed=True, color=color, thickness=2)

    result = cv2.addWeighted(overlay_fill, alpha, img_out, 1 - alpha, 0)
    return result

# --- GIAO DI·ªÜN STREAMLIT ---
st.set_page_config(page_title="AI Endoscopy Diagnosis", layout="wide")
st.title("ü©∫ H·ªá th·ªëng ph√¢n t√≠ch n·ªôi soi tai")
st.sidebar.header("C·∫•u h√¨nh")

checkpoint_path = st.sidebar.text_input("ƒê∆∞·ªùng d·∫´n Checkpoint", "/mnt/mmlab2024nas/khanhnq/check_point_deeplabv3/log14/best_model.pth")
uploaded_file = st.sidebar.file_uploader("Ch·ªçn ·∫£nh n·ªôi soi...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # 1. Load Model
    with st.spinner('ƒêang t·∫£i m√¥ h√¨nh...'):
        
        model, device = load_model(checkpoint_path)

    # 2. ƒê·ªçc ·∫£nh
    img_pil = Image.open(uploaded_file).convert("RGB")
    org_w, org_h = img_pil.size
    img_np = np.array(img_pil)

    # 3. Ti·ªÅn x·ª≠ l√Ω & D·ª± ƒëo√°n
    transform = get_transform(False)
    input_tensor = transform(tv_tensors.Image(img_pil)).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(input_tensor)
        seg_output, pred_cls = outputs['out'], outputs['cls']
        
        # L·∫•y nh√£n ph√¢n lo·∫°i
        cls_idx = torch.softmax(pred_cls, dim=1).argmax(dim=1).item()
        
        # Upscale mask
        logits_up = Fnn.interpolate(seg_output, size=(org_h, org_w), mode='bilinear', align_corners=False)
        pred_mask = torch.argmax(logits_up, dim=1).squeeze(0).cpu()

    # 4. T·∫°o ·∫£nh Overlay
    overlay_res = draw_polygon_overlay(img_np, pred_mask)
    Image.fromarray(overlay_res).save(os.path.join('/home/khanhnq/Experiment/Mask_RCNN/res_image',  f"overlay_1.png"))
    # 5. Hi·ªÉn th·ªã ·∫£nh
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("·∫¢nh g·ªëc")
        st.image(img_pil, use_container_width=True)
    with col2:
        st.subheader("K·∫øt qu·∫£ Segmentation")
        st.image(overlay_res, use_container_width=True)

    # TH√äM CH√ö TH√çCH M√ÄU (LEGEND) ·ªû ƒê√ÇY
    st.markdown("### üí° Ch√∫ th√≠ch c√°c v√πng m√†u:")
    cols = st.columns(3)

    # ƒê·ªãnh nghƒ©a CSS cho c√°c "n√∫t" ch√∫ th√≠ch
    def color_block(color_hex, text):
        return f"""
        <div style="
            display: flex; 
            align-items: center; 
            background-color: #f0f2f6; 
            padding: 10px; 
            border-radius: 10px; 
            border-left: 10px solid {color_hex};
            margin-bottom: 10px;">
            <span style="font-weight: bold; color: #31333F; margin-left: 10px;">{text}</span>
        </div>
        """

    with cols[0]:
        st.markdown(color_block("#00FF08", "C√°n x∆∞∆°ng b√∫a (Xanh)"), unsafe_allow_html=True)
    with cols[1]:
        st.markdown(color_block("#FFA500", "Tam gi√°c s√°ng (Cam)"), unsafe_allow_html=True)
    with cols[2]:
        st.markdown(color_block("#FFFF00", "B√≥ng kh√≠ (V√†ng)"), unsafe_allow_html=True)

    # 6. G·ªçi Gemini API
    st.divider()
    st.subheader("ü§ñ Ph√¢n t√≠ch ")
    
    with st.spinner('ƒêang ph√¢n t√≠ch...'):
        # Chuy·ªÉn ·∫£nh overlay sang bytes
        img_byte_arr = io.BytesIO()
        Image.fromarray(overlay_res).save(img_byte_arr, format='PNG')
        image_part = types.Part.from_bytes(data=img_byte_arr.getvalue(), mime_type="image/png")

        prompt =  """
            B·∫°n l√† m·ªôt chuy√™n gia n·ªôi soi Tai M≈©i H·ªçng gi√†u kinh nghi·ªám.
            
            NHI·ªÜM V·ª§: Ph√¢n t√≠ch ·∫£nh m√†ng nhƒ© d·ª±a tr√™n mask m√†u:
            Mask xanh l√°: C√°n b√∫a
            Mask cam: Tam gi√°c s√°ng
            Mask v√†ng: B√≥ng kh√≠
            
            QUY T·∫ÆC PH·∫¢N H·ªíI:
            Ch·ªâ tr·∫£ l·ªùi TR√äN 1 D√íNG DUY NH·∫§T.
            N·∫øu c√≥ mask n√†o tr√™n h√¨nh, ph·∫£i ghi ch√∫ m√†u mask ngay sau t√™n b·ªô ph·∫≠n ƒë√≥ trong m√¥ t·∫£, n·∫øu kh√¥ng c√≥ th√¨ kh√¥ng ghi ch√∫ v√†o m√¥ t·∫£.
            V√≠ d·ª•:
            C√≥: "tam gi√°c s√°ng r√µ (mask cam), c√°n x∆∞∆°ng b√∫a th·∫•y r√µ (mask xanh) ".
            kh√¥ng c√≥: "Tam gi√°c s√°ng m·∫•t, c√°n x∆∞∆°ng b√∫a m·∫•t".
            
            Ch·ªâ ch·ªçn 1 trong c√°c m·∫´u d∆∞·ªõi ƒë√¢y ƒë·ªÉ ƒëi·ªÅn th√¥ng tin:
            M·∫´u 1: M√¥ T·∫£: M√†ng nhƒ© nguy√™n v·∫πn, tam gi√°c s√°ng r√µ , c√°n x∆∞∆°ng b√∫a th·∫•y r√µ
            M·∫´u 2: M√¥ T·∫£: M√†ng nhƒ© nguy√™n v·∫πn, tam gi√°c s√°ng kh√¥ng th·∫•y, c√°n x∆∞∆°ng b√∫a th·∫•y r√µ
            M·∫´u 3: M√¥ T·∫£: M√†ng nhƒ© cƒÉng ph·ªìng/sung huy·∫øt, tam gi√°c s√°ng m·∫•t/c√≤n , m·∫•t/c√≤n v·ªã tr√≠ c√°n x∆∞∆°ng b√∫a
            M·∫´u 4: M√¥ T·∫£: M√†ng nhƒ© m√†u h·ªï ph√°ch/ b√≥ng kh√≠ sau m√†ng nhƒ© , tam gi√°c m·∫•t/c√≤n , c√°n x∆∞∆°ng b√∫a c√≤n/ m·∫•t .
            M·∫´u 5: M√¥ T·∫£: M√†ng nhƒ© th·ªßng, tam gi√°c s√°ng c√≤n/ m·∫•t , c√°n x∆∞∆°ng b√∫a c√≤n/ m·∫•t .
            
            L∆∞u √Ω: "/" l√† ch·ªçn 1 trong 2. Kh√¥ng ƒë·ªÉ l·∫°i d·∫•u "/" trong k·∫øt qu·∫£ cu·ªëi c√πng.
            """
        
        try:
            response = client.models.generate_content(
                model="gemini-2.5-pro", # C·∫≠p nh·∫≠t model name n·∫øu c·∫ßn
                contents=[prompt, image_part],
            )
            
            # HI·ªÇN TH·ªä K·∫æT QU·∫¢ CU·ªêI C√ôNG
            st.info(f"**K·∫øt qu·∫£ ch·∫©n ƒëo√°n (Model):** {CLASS_NAMES[cls_idx]} (ID: {cls_idx})")
            st.success(f" {response.text}")
            
        except Exception as e:
            st.error(f"L·ªói khi g·ªçi Gemini API: {e}")

else:
    st.info("Vui l√≤ng t·∫£i ·∫£nh l√™n t·ª´ thanh b√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu.")